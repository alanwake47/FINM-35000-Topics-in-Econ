{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Response (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional for extra credit. Must be completed individually.\n",
    "\n",
    "Read Aruoba and Drechsel (2022) and answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Describe the natural language processing technique that the authors use. What do you like about it? What are its shortcomings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The natural language processing (NLP) techniques that Aruoba and Drechsel (2022) use in their paper are:\n",
    "\n",
    "1. Tokenization: The authors split the FOMC documents into individual tokens, which can be words, punctuation marks, or other symbols.\n",
    "2. Lemmatization: The authors convert the tokens to their base forms. For example, the tokens \"walks,\" \"walked,\" and \"walking\" would all be converted to the lemma \"walk.\"\n",
    "3. Stop word removal: The authors remove common words, such as \"the,\" \"is,\" and \"of,\" from the tokens.\n",
    "4. Part-of-speech tagging: The authors assign a part-of-speech (POS) tag to each token. For example, the token \"walk\" could be tagged as a verb, noun, or adjective.\n",
    "5. Sentiment analysis: The authors use a sentiment analysis tool to extract sentiment indicators from the tokens. These sentiment indicators capture the tone of the documents and the authors' views on economic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">One of the things that I like about the authors' NLP approach is that it is relatively simple and straightforward. This makes it easy to understand and reproduce. Additionally, the authors use a variety of NLP techniques, which helps to ensure that they are capturing a wide range of information from the FOMC documents.\n",
    ">\n",
    ">However, there are also some shortcomings to the authors' NLP approach. One shortcoming is that it is only able to capture the explicit meaning of the FOMC documents. The authors do not attempt to capture the implicit meaning of the documents, such as the authors' intentions or the underlying motivations for their statements. Additionally, the authors' NLP approach is only as good as the sentiment analysis tool that they use. If the sentiment analysis tool is not accurate, then the authors' results will be skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Summarize (in your own words) the findings discussed in Section 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In Section 4, Aruoba and Drechsel (2022) compare the properties of their monetary policy shocks to those of shocks identified using traditional methods. They find that their shocks are more persistent, have a larger impact on inflation, and are more correlated with changes in asset prices. They also find that their shocks are different from those identified using traditional methods, suggesting that their method is capturing additional information from the FOMC documents.\n",
    ">\n",
    ">The authors also find that the systematic component of monetary policy is much more important than the exogenous component. This means that the vast majority of the variation in monetary policy is due to predictable factors, such as the Fed's response to economic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary** <br>\n",
    "Traditional methods of identifying monetary policy shocks typically focus on numerical forecasts, which are limited in their ability to capture the full range of information contained in the FOMC documents. Aruoba and Drechsel's NLP approach overcomes this limitation by extracting sentiment indicators from the FOMC documents. The authors find that their shocks are more persistent, have a larger impact on inflation, and are more correlated with changes in asset prices than shocks identified using traditional methods. Additionally, they find that the systematic component of monetary policy is much more important than the exogenous component. These findings suggest that the authors' NLP approach is a valuable tool for identifying monetary policy shocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What questions do you have after reading the paper?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a few questions after reading the paper:\n",
    "\n",
    "1. How well does the authors' NLP approach generalize to other countries and central banks?\n",
    "2. How does the authors' NLP approach compare to other NLP-based methods for identifying monetary policy shocks?\n",
    "3. How can the authors' NLP approach be used to identify the sources of monetary policy uncertainty?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
